{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Ch 16\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    X = X.reshape(len(X), 784)\n",
    "    X = X.astype('float32')/255\n",
    "    return X\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = normalize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "np.random.seed(42)\n",
    "optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "gen = Sequential()\n",
    "gen.add(Dense(256, input_dim=input_dim))\n",
    "gen.add(LeakyReLU(alpha=0.2))\n",
    "gen.add(BatchNormalization())\n",
    "gen.add(Dense(512))\n",
    "gen.add(LeakyReLU(alpha=0.2))\n",
    "gen.add(BatchNormalization())\n",
    "gen.add(Dense(1024))\n",
    "gen.add(LeakyReLU(alpha=0.2))\n",
    "gen.add(BatchNormalization())\n",
    "gen.add(Dense(784, activation='sigmoid'))\n",
    "gen.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dsc = Sequential()\n",
    "dsc.add(Dense(1024, input_dim=784))\n",
    "dsc.add(LeakyReLU(alpha=0.2))\n",
    "dsc.add(Dropout(0.3))\n",
    "dsc.add(Dense(512))\n",
    "dsc.add(LeakyReLU(alpha=0.2))\n",
    "dsc.add(Dropout(0.3))\n",
    "dsc.add(Dense(256))\n",
    "dsc.add(LeakyReLU(alpha=0.2))\n",
    "dsc.add(Dropout(0.3))\n",
    "dsc.add(Dense(1, activation='sigmoid'))  \n",
    "dsc.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(dnn, flag):\n",
    "    dnn.trainable = flag\n",
    "    for l in dnn.layers:\n",
    "        l.trainable = flag\n",
    "        \n",
    "make_trainable(dsc, False)\n",
    "inputs = Input(shape=(input_dim, ))\n",
    "hidden = gen(inputs)\n",
    "output = dsc(hidden)\n",
    "gan = Model(inputs, output)\n",
    "gan.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noise(n, z):\n",
    "    return np.random.normal(0, 1, size=(n, z))\n",
    "\n",
    "def plot_sample(n, z):\n",
    "    samples = gen.predict(create_noise(n, z))\n",
    "    plt.figure(figsize=(15,3))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, (i+1))\n",
    "        plt.imshow(samples[i].reshape(28, 28), \n",
    "                   cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code takes several hours\n",
    "#epochs = 100\n",
    "#batch_size = 128\n",
    "#batch_no = int(len(X_train) / batch_size)\n",
    "#gen_errors, dsc_errors = (list(), list())\n",
    "\n",
    "#for i in range(0, epochs):\n",
    "    #for j in range(batch_no): \n",
    "      \n",
    "        # Drawing a random sample of the training set\n",
    "       # rand_sample = np.random.randint(0, len(X_train), size=batch_size)\n",
    "        #image_batch = X_train[rand_sample]\n",
    "        \n",
    "        # Creating noisy inputs for the generator\n",
    "        #input_noise = create_noise(batch_size, input_dim)\n",
    "\n",
    "        # Generating fake images from the noisy input\n",
    "        #generated_images = gen.predict(input_noise)\n",
    "        #X = np.concatenate((image_batch, generated_images))\n",
    "        \n",
    "        # Creating somehow noisy labels\n",
    "        #y = np.concatenate([[0.9]*batch_size, [0.0]*batch_size])\n",
    "\n",
    "        # Training discriminator to distinguish fakes from real ones\n",
    "        #make_trainable(dsc, True)\n",
    "        #dsc_loss = dsc.train_on_batch(X, y)\n",
    "        #make_trainable(dsc, False)\n",
    "\n",
    "        # Trainining generating fakes\n",
    "        #input_noise = create_noise(batch_size, input_dim)\n",
    "        #fakes = np.ones(batch_size)\n",
    "        #for _ in range(4):\n",
    "          #gen_loss = gan.train_on_batch(input_noise, fakes)\n",
    "\n",
    "    # Recording the losses\n",
    "    #gen_errors.append(gen_loss)\n",
    "    #dsc_errors.append(dsc_loss)\n",
    "\n",
    "    # Showing intermediate results\n",
    "    #if i % 10 == 0:\n",
    "      #print(\"Epoch %i\" % i)\n",
    "      #plot_sample(10, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in ./anaconda3/lib/python3.6/site-packages (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.7 in ./anaconda3/lib/python3.6/site-packages (from h5py) (1.15.4)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.6/site-packages (from h5py) (1.11.0)\n",
      "Collecting gym\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/38/87aefd5388f6062267384b7e8f97dbc27c54b3e6137a5148b43d5c10890c/gym-0.13.1.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 3.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in ./anaconda3/lib/python3.6/site-packages (from gym) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./anaconda3/lib/python3.6/site-packages (from gym) (1.15.4)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.6/site-packages (from gym) (1.11.0)\n",
      "Collecting pyglet<=1.3.2,>=1.2.0 (from gym)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 8.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle~=1.2.0 (from gym)\n",
      "  Downloading https://files.pythonhosted.org/packages/09/f4/4a080c349c1680a2086196fcf0286a65931708156f39568ed7051e42ff6a/cloudpickle-1.2.1-py2.py3-none-any.whl\n",
      "Collecting future (from pyglet<=1.3.2,>=1.2.0->gym)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 10.9MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gym, future\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/apple/Library/Caches/pip/wheels/95/14/8e/b4f5c72600f654312b40c0844d4c23f146f291c48ac7a5df62\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/apple/Library/Caches/pip/wheels/0c/61/d2/d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e\n",
      "Successfully built gym future\n",
      "\u001b[31mERROR: spyder 3.3.2 requires pyqt5<5.10; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "Installing collected packages: future, pyglet, cloudpickle, gym\n",
      "  Found existing installation: cloudpickle 0.5.3\n",
      "    Uninstalling cloudpickle-0.5.3:\n",
      "      Successfully uninstalled cloudpickle-0.5.3\n",
      "Successfully installed cloudpickle-1.2.1 future-0.17.1 gym-0.13.1 pyglet-1.3.2\n",
      "WARNING conda.base.context:use_only_tar_bz2(632): Conda is constrained to only using the old .tar.bz2 file format because you have conda-build installed, and it is <3.18.3.  Update or remove conda-build to get smaller downloads and faster extractions.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - ffmpe\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/menpo/osx-64\n",
      "  - https://conda.anaconda.org/menpo/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ch 17\n",
    "!pip install h5py\n",
    "!pip install gym\n",
    "!conda install -c menpo ffmpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "np.random.seed(42), env.seed(42) \n",
    "nb_actions = env.action_space.n\n",
    "input_shape = (1, env.observation_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode concluded after 24 timesteps\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "for t in range(200):\n",
    "    env.render()\n",
    "    act = env.action_space.sample()\n",
    "    obs, rwrd, done, info = env.step(act)\n",
    "    if done:\n",
    "        print(\"Episode concluded after %i timesteps\" % (t+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-rl\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/87/4b57eff8e4bd834cea0a75cd6c58198c9e42be29b600db9c14fafa72ec07/keras-rl-0.4.2.tar.gz (40kB)\n",
      "\u001b[K     |████████████████████████████████| 40kB 4.5MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: keras>=2.0.7 in ./anaconda3/lib/python3.6/site-packages (from keras-rl) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.0.7->keras-rl) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.14 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.0.7->keras-rl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.0.7->keras-rl) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.6/site-packages (from keras>=2.0.7->keras-rl) (3.12)\n",
      "Requirement already satisfied: h5py in ./anaconda3/lib/python3.6/site-packages (from keras>=2.0.7->keras-rl) (2.7.1)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.0.7->keras-rl) (1.0.6)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.0.7->keras-rl) (1.0.5)\n",
      "Building wheels for collected packages: keras-rl\n",
      "  Building wheel for keras-rl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/apple/Library/Caches/pip/wheels/7d/4d/84/9254c9f2e8f51865cb0dac8e79da85330c735551d31f73c894\n",
      "Successfully built keras-rl\n",
      "Installing collected packages: keras-rl\n",
      "Successfully installed keras-rl-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-rl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "from keras.layers import Flatten, Dropout \n",
    "from keras.optimizers import Adam\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                60        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 26        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(12))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear')) \n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 30000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 45s 5ms/step - reward: 1.0000\n",
      "247 episodes - episode_reward: 39.733 [8.000, 200.000] - loss: 3.926 - mean_q: 20.007\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 43s 4ms/step - reward: 1.0000\n",
      "54 episodes - episode_reward: 186.796 [67.000, 200.000] - loss: 9.415 - mean_q: 47.932\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 43s 4ms/step - reward: 1.0000\n",
      "done, took 132.046 seconds\n"
     ]
    }
   ],
   "source": [
    "policy = EpsGreedyQPolicy(eps=0.3)\n",
    "memory = SequentialMemory(limit=50000, \n",
    "                          window_length=1)\n",
    "\n",
    "dqn = DQNAgent(model=model, \n",
    "               nb_actions=nb_actions, \n",
    "               memory=memory, \n",
    "               nb_steps_warmup=50, \n",
    "               target_model_update=0.01, \n",
    "               policy=policy)\n",
    "\n",
    "dqn.compile(Adam(lr=0.001))\n",
    "\n",
    "training = dqn.fit(env, nb_steps=30000, \n",
    "                   visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies to be installed for this cod\n",
    "#env = gym.make('CartPole-v0')\n",
    "#mon = gym.wrappers.Monitor(env, \n",
    "                          # \"./gym-results\",\n",
    "                           #force=True)\n",
    "#mon.reset()\n",
    "#dqn.test(mon, nb_episodes=1, visualize=True)\n",
    "#mon.close()\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code not working\n",
    "#import io\n",
    "#import base64\n",
    "#from IPython.display import HTML\n",
    "\n",
    "#template = './gym-results/openaigym.video.%s.video000001.mp4'\n",
    "#video = io.open(template % mon.file_infix, 'r+b').read()\n",
    "#encoded = base64.b64encode(video)\n",
    "#HTML(data='''\n",
    "#<video width=\"520\" height=\"auto\" alt=\"test\" controls>\n",
    "#<source src=\"data:video/mp4;base64,{0}\"\n",
    "# type=\"video/mp4\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
